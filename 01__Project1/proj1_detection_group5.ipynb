{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Object Detection - Group 5\n",
    "\n",
    "## Team Members:\n",
    "\n",
    "- Steve Morris Kungu\n",
    "- Malcolm Saeden\n",
    "- Ole Magnus Laerum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# ðŸ“Œ Import Libraries\n",
    "# ==============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox  # Ensure this is imported\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# ðŸ“Œ DEFINE IMAGE PROCESSING FUNCTIONS\n",
    "# ==============================\n",
    "\n",
    "def median_filter(image):\n",
    "    return cv2.medianBlur(image, 5)\n",
    "\n",
    "\n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def thresholding(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = grayscale(image)\n",
    "    otsu_threshold, binary_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_img, otsu_threshold\n",
    "\n",
    "\n",
    "def contour_detection(image, thickness=4):\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = grayscale(image)\n",
    "    else:\n",
    "        gray = image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contoured_img = np.zeros_like(image)\n",
    "    cv2.drawContours(contoured_img, contours, -1, (255), thickness)\n",
    "\n",
    "    return contoured_img\n",
    "\n",
    "\n",
    "def invert_colors(image):\n",
    "    return cv2.bitwise_not(image)\n",
    "\n",
    "\n",
    "def crop_image(image, crop_top, crop_bottom, crop_left, crop_right):\n",
    "    h, w = image.shape[:2]\n",
    "    crop_bottom = min(crop_bottom, h - crop_top)\n",
    "    crop_right = min(crop_right, w - crop_left)\n",
    "    cropped = image[crop_top:h - crop_bottom, crop_left:w - crop_right]\n",
    "\n",
    "    if cropped.size == 0:\n",
    "        return None  # Return None if the crop is invalid\n",
    "    return cropped\n",
    "\n",
    "\n",
    "def resize_image(image, size=(500, 500)):\n",
    "    return cv2.resize(image, size) if image is not None and image.size > 0 else None\n",
    "\n",
    "\n",
    "def dilation(image, kernel_size=5):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "\n",
    "def erosion(image, kernel_size=5):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "\n",
    "def opening(image, kernel_size=5):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "def closing(image, kernel_size=5):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "def euclidean_distance(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = grayscale(image)\n",
    "    dist_transform = cv2.distanceTransform(image, cv2.DIST_L2, 5)\n",
    "    return cv2.normalize(dist_transform, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "\n",
    "def labeling(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = grayscale(image)\n",
    "\n",
    "    _, binary_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "    output_img = np.zeros((*image.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    colors = np.random.randint(0, 255, size=(num_labels, 3), dtype=np.uint8)\n",
    "\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            label = labels[y, x]\n",
    "            if label > 0:\n",
    "                output_img[y, x] = colors[label]\n",
    "\n",
    "    return output_img, num_labels - 1  # Exclude background\n",
    "\n",
    "\n",
    "def labeling_cc(image, is_black_objects=True):\n",
    "    binary = (image == 255).astype(np.uint8)  # White objects on black background\n",
    "\n",
    "    rows, cols = binary.shape\n",
    "    labeled_img = np.zeros((rows, cols), dtype=np.int32)\n",
    "\n",
    "    # 8-connectivity neighbors\n",
    "    neighbors = [(-1, -1),  (-1, 0),    (-1, 1),\n",
    "                 (0, -1),               (0, 1),\n",
    "                 (1, -1),   (1, 0),     (1, 1)]\n",
    "\n",
    "    N = 0\n",
    "    found = True\n",
    "    while found:\n",
    "        found = False\n",
    "\n",
    "        # SEARCH: Find an unlabeled object pixel\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if binary[i, j] == 1 and labeled_img[i, j] == 0:\n",
    "                    N += 1\n",
    "                    labeled_img[i, j] = 255\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "\n",
    "        # PROPAGATION: Spread the label to all connected pixels\n",
    "        if found:\n",
    "            finished = False\n",
    "            while not finished:\n",
    "                finished = True\n",
    "                for i in range(rows):\n",
    "                    for j in range(cols):\n",
    "                        if binary[i, j] == 1 and labeled_img[i, j] == 0:\n",
    "                            for di, dj in neighbors:\n",
    "                                ni, nj = i + di, j + dj\n",
    "\n",
    "                                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                                    if labeled_img[ni, nj] == 255:\n",
    "                                        labeled_img[i, j] = 255\n",
    "                                        finished = False\n",
    "                                        break\n",
    "\n",
    "    return labeled_img, N\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def BFS_labelling(image):\n",
    "    binary = (image == 255).astype(np.uint8)  # White objects on black background\n",
    "\n",
    "    rows, cols = binary.shape\n",
    "    labeled_img = np.zeros((rows, cols), dtype=np.uint8)  # Keep background black\n",
    "\n",
    "    # 8-connectivity neighbors for each quadrant\n",
    "    quadrant_neighbors = [\n",
    "        [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)],\n",
    "        [(1, 1), (1, 0), (1, -1), (0, 1), (0, -1), (-1, 1), (-1, 0), (-1, -1)],\n",
    "        [(1, -1), (1, 0), (1, 1), (0, -1), (0, 1), (-1, -1), (-1, 0), (-1, 1)],\n",
    "        [(-1, 1), (-1, 0), (-1, -1), (0, 1), (0, -1), (1, 1), (1, 0), (1, -1)]\n",
    "    ]\n",
    "\n",
    "    N = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if binary[i, j] == 1 and labeled_img[i, j] == 0:\n",
    "                N += 1\n",
    "                queue = deque([(i, j)])\n",
    "                labeled_img[i, j] = 255  # Set object to white\n",
    "\n",
    "                # BFS\n",
    "                for neighbors in quadrant_neighbors:\n",
    "                    local_queue = deque(queue)\n",
    "                    while local_queue:\n",
    "                        x, y = local_queue.popleft()\n",
    "                        for dx, dy in neighbors:\n",
    "                            nx, ny = x + dx, y + dy\n",
    "                            if 0 <= nx < rows and 0 <= ny < cols and binary[nx, ny] == 1 and labeled_img[nx, ny] == 0:\n",
    "                                labeled_img[nx, ny] = 255  # Spread white label\n",
    "                                local_queue.append((nx, ny))\n",
    "\n",
    "    return labeled_img, N  # Return labeled image with white objects and object count\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ðŸ“Œ GUI CLASS\n",
    "# ==============================\n",
    "\n",
    "class ImageProcessorApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Image Processing GUI\")\n",
    "        self.root.geometry(\"1500x700\")\n",
    "\n",
    "        # Variables\n",
    "        self.image_path = \"\"\n",
    "        self.original_image = None\n",
    "        self.processed_image = None\n",
    "        self.is_grayscale = False\n",
    "        self.otsu_threshold = None\n",
    "        self.num_objects = 0\n",
    "        self.kernel_size = tk.IntVar(value=5)\n",
    "        self.crop_top = tk.IntVar(value=0)\n",
    "        self.crop_bottom = tk.IntVar(value=0)\n",
    "        self.crop_left = tk.IntVar(value=0)\n",
    "        self.crop_right = tk.IntVar(value=0)\n",
    "        self.line_dots_size = 25\n",
    "\n",
    "        # UI Layout\n",
    "        self.left_frame = ttk.Frame(root)\n",
    "        self.left_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "        self.right_frame = ttk.Frame(root)\n",
    "        self.right_frame.pack(side=tk.RIGHT, padx=10, pady=10, fill=tk.Y, expand=True)\n",
    "\n",
    "        self.histogram_frame = ttk.Frame(root)\n",
    "        self.histogram_frame.pack(side=tk.RIGHT, padx=10, pady=10)\n",
    "\n",
    "        # Image Canvas\n",
    "        self.canvas = tk.Canvas(self.left_frame, width=500, height=500, bg=\"gray\")\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Load, Save, and Reset Buttons in a Single Frame\n",
    "        self.top_buttons_frame = ttk.Frame(self.left_frame)\n",
    "        self.top_buttons_frame.pack(pady=10)\n",
    "\n",
    "        self.btn_load = ttk.Button(self.top_buttons_frame, text=\"Load Image\", command=self.load_image)\n",
    "        self.btn_load.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_save = ttk.Button(self.top_buttons_frame, text=\"Save Image\", command=self.save_image)\n",
    "        self.btn_save.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_reset = ttk.Button(self.top_buttons_frame, text=\"Reset Image\", command=self.reset_image)\n",
    "        self.btn_reset.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Center Buttons in Right Frame\n",
    "        self.button_container = ttk.Frame(self.right_frame)\n",
    "        self.button_container.pack(expand=True)\n",
    "\n",
    "        self.status_label = ttk.Label(self.left_frame, text=\"Status: Ready\", foreground=\"blue\")\n",
    "        self.status_label.pack(pady=10)\n",
    "\n",
    "        # Processing Buttons\n",
    "\n",
    "        # Checkbox for Preprocessing (Grayscale â†’ Median Filter â†’ Threshold â†’ Opening â†’ Closing)\n",
    "        self.is_preprocess = tk.BooleanVar(value=False)\n",
    "        self.chk_preprocess = ttk.Checkbutton(\n",
    "            self.button_container, text=\"Preprocess Image (only bean-photos)\",\n",
    "            variable=self.is_preprocess, command=self.check_preprocess\n",
    "        )\n",
    "        self.chk_preprocess.pack(pady=5)\n",
    "\n",
    "        # Checkbox for Object Color Selection (Triggers pop-up)\n",
    "        self.is_black_objects = tk.BooleanVar(value=False)\n",
    "        self.chk_black_objects = ttk.Checkbutton(\n",
    "            self.button_container, text=\"Tick if the objects of interest are black after Grayscale?\",\n",
    "            variable=self.is_black_objects, command=self.check_black_objects\n",
    "        )\n",
    "        self.chk_black_objects.pack(pady=5)\n",
    "\n",
    "        # Frame for text\n",
    "        separator_frame = ttk.Frame(self.button_container)\n",
    "        separator_frame.pack(pady=5)\n",
    "\n",
    "        self.label_between = ttk.Label(separator_frame, text= f\"{'-' * self.line_dots_size } Manually add filters: {'-' * self.line_dots_size}\")\n",
    "        self.label_between.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Grayscale, Thresholding, and Invert Colors (Same Row)\n",
    "        processing_frame1 = ttk.Frame(self.button_container)\n",
    "        processing_frame1.pack(pady=5)\n",
    "\n",
    "        self.btn_grayscale = ttk.Button(processing_frame1, text=\"Grayscale\",\n",
    "                                        command=lambda: self.apply_filter(grayscale))\n",
    "        self.btn_grayscale.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_thresholding = ttk.Button(processing_frame1, text=\"Thresholding\", command=self.apply_thresholding)\n",
    "        self.btn_thresholding.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_invert = ttk.Button(processing_frame1, text=\"Invert Colors\",\n",
    "                                     command=lambda: self.apply_filter(invert_colors))\n",
    "        self.btn_invert.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Median Filter, Opening, and Closing (Same Row)\n",
    "        morphology_frame1 = ttk.Frame(self.button_container)\n",
    "        morphology_frame1.pack(pady=5)\n",
    "\n",
    "        self.btn_median = ttk.Button(morphology_frame1, text=\"Median Filter\",\n",
    "                                     command=lambda: self.apply_filter(median_filter))\n",
    "        self.btn_median.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_opening = ttk.Button(morphology_frame1, text=\"Opening\", command=lambda: self.apply_filter(\n",
    "            lambda img: opening(img, self.kernel_size.get())))\n",
    "        self.btn_opening.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_closing = ttk.Button(morphology_frame1, text=\"Closing\", command=lambda: self.apply_filter(\n",
    "            lambda img: closing(img, self.kernel_size.get())))\n",
    "        self.btn_closing.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Dilation and Erosion (Same Row)\n",
    "        morphology_frame2 = ttk.Frame(self.button_container)\n",
    "        morphology_frame2.pack(pady=5)\n",
    "\n",
    "        self.btn_dilation = ttk.Button(morphology_frame2, text=\"Dilation\", command=lambda: self.apply_filter(\n",
    "            lambda img: dilation(img, self.kernel_size.get())))\n",
    "        self.btn_dilation.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_erosion = ttk.Button(morphology_frame2, text=\"Erosion\", command=lambda: self.apply_filter(\n",
    "            lambda img: erosion(img, self.kernel_size.get())))\n",
    "        self.btn_erosion.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Edge Detection and Euclidean Distance (Same Row)\n",
    "        processing_frame2 = ttk.Frame(self.button_container)\n",
    "        processing_frame2.pack(pady=5)\n",
    "\n",
    "        self.btn_contour = ttk.Button(processing_frame2, text=\"Contour Detection\",\n",
    "                                   command=lambda: self.apply_filter(contour_detection))\n",
    "        self.btn_contour.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_euclidean = ttk.Button(processing_frame2, text=\"Euclidean Distance\",\n",
    "                                        command=lambda: self.apply_filter(euclidean_distance))\n",
    "        self.btn_euclidean.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        \n",
    "        # Frame for text\n",
    "        separator_frame = ttk.Frame(self.button_container)\n",
    "        separator_frame.pack(pady=5)\n",
    "\n",
    "        self.label_between = ttk.Label(separator_frame, text= f\"{'-' * self.line_dots_size} Detecting objects: {'-' * self.line_dots_size} \")\n",
    "        self.label_between.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Label Objects and Count Objects Only (Same Row)\n",
    "        labeling_frame = ttk.Frame(self.button_container)\n",
    "        labeling_frame.pack(pady=5)\n",
    "\n",
    "        self.btn_labeling = ttk.Button(labeling_frame, text=\"Color Objects\", command=self.apply_labeling)\n",
    "        self.btn_labeling.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_count_objects = ttk.Button(labeling_frame, text=\"Count Objects Only\", command=self.count_objects_only)\n",
    "        self.btn_count_objects.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Frame for Labeling Buttons (Align them side by side)\n",
    "        labeling_frame = ttk.Frame(self.button_container)\n",
    "        labeling_frame.pack(pady=5)\n",
    "\n",
    "        # Add Connected Component Labeling (CC) Button\n",
    "        self.btn_labeling_cc = ttk.Button(labeling_frame, text=\"Label Objects (Connected Components CC)\", command=self.apply_labeling_cc)\n",
    "        self.btn_labeling_cc.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Add BFS Labeling Button\n",
    "        self.btn_BFS_labelling = ttk.Button(labeling_frame, text=\"Label Objects (CC with BFS)\",\n",
    "                                            command=self.apply_BFS_labelling)\n",
    "        self.btn_BFS_labelling.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Crop Controls in a Single Row\n",
    "        crop_frame = ttk.Frame(self.button_container)\n",
    "        crop_frame.pack(pady=5)\n",
    "\n",
    "        ttk.Label(crop_frame, text=\"Top:\").pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Entry(crop_frame, textvariable=self.crop_top, width=5).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        ttk.Label(crop_frame, text=\"Bottom:\").pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Entry(crop_frame, textvariable=self.crop_bottom, width=5).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        ttk.Label(crop_frame, text=\"Left:\").pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Entry(crop_frame, textvariable=self.crop_left, width=5).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        ttk.Label(crop_frame, text=\"Right:\").pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Entry(crop_frame, textvariable=self.crop_right, width=5).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Crop Button on the Same Row\n",
    "        self.btn_crop = ttk.Button(crop_frame, text=\"Apply Crop\", command=self.apply_crop)\n",
    "        self.btn_crop.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "    # DONT TOUCH BELOW DEFINITIONS\n",
    "    def check_black_objects(self):\n",
    "        \"\"\" Inverts the image automatically when the checkbox is ticked. \"\"\"\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            self.is_black_objects.set(False)  # Prevent ticking if no image is loaded\n",
    "            return\n",
    "\n",
    "        if self.is_black_objects.get():  # If checkbox is checked (Objects are black)\n",
    "            messagebox.showinfo(\"Invert Colors\", \"Inverting objects to white.\")  # Show confirmation\n",
    "\n",
    "            # Apply inversion and display the updated image\n",
    "            self.processed_image = invert_colors(self.processed_image)\n",
    "            self.display_image(self.processed_image)\n",
    "            self.status_label.config(text=\"Status: Objects Inverted to White\")\n",
    "\n",
    "    def check_preprocess(self):\n",
    "        \"\"\" Automatically preprocess the image if the checkbox is ticked. \n",
    "            This functionality is tuned for photos of beans, not for instance spiral pictures. \n",
    "            This greyscale -> median filter -> thresholding -> opening -> closing procedure is made specifically to fit the process of preprocessing the bean-photos from the raspberry pi camera.\n",
    "        \"\"\"\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            self.is_preprocess.set(False)  # Prevent ticking if no image is loaded\n",
    "            return\n",
    "\n",
    "        if self.is_preprocess.get():  # If checkbox is ticked, apply preprocessing\n",
    "            messagebox.showinfo(\"Preprocessing\",\n",
    "                                \"Applying preprocessing steps: Grayscale â†’ Median Filter â†’ Threshold â†’ Opening â†’ Closing.\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Apply preprocessing steps in order\n",
    "            self.processed_image = grayscale(self.processed_image)\n",
    "            self.processed_image = median_filter(self.processed_image)\n",
    "            self.processed_image, _ = thresholding(self.processed_image)\n",
    "            self.processed_image = opening(self.processed_image)\n",
    "            self.processed_image = closing(self.processed_image)\n",
    "\n",
    "            elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "            # Update the displayed image\n",
    "            self.display_image(self.processed_image)\n",
    "            self.status_label.config(text=f\"Status: Preprocessing Completed in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def apply_contour_detection(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Apply contour detection with thickened lines\n",
    "        self.processed_image = contour_detection(self.processed_image, thickness=3)\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "        self.display_image(self.processed_image)\n",
    "        self.status_label.config(text=f\"Status: Contour Detection Applied in {elapsed_time:.2f} ms\")\n",
    "        print(f\"Process Step: Contour Detection completed in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def apply_crop(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        cropped = crop_image(self.processed_image, self.crop_top.get(), self.crop_bottom.get(), self.crop_left.get(),\n",
    "                             self.crop_right.get())\n",
    "\n",
    "        if cropped is None or cropped.size == 0:\n",
    "            messagebox.showerror(\"Error\", \"Invalid crop dimensions! Please adjust and try again.\")\n",
    "            return\n",
    "\n",
    "        self.processed_image = resize_image(cropped)\n",
    "        self.display_image(self.processed_image)\n",
    "        self.status_label.config(text=\"Status: Crop Applied\")\n",
    "\n",
    "    def apply_filter(self, filter_function):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.processed_image = filter_function(self.processed_image)\n",
    "\n",
    "        # Ask user if objects are black and invert if confirmed\n",
    "        if not hasattr(self, \"inverted\"):\n",
    "            response = messagebox.askyesno(\"Invert Colors\", \"Are the objects black? If yes, they will be inverted.\")\n",
    "            if response:  # User clicked \"Yes\"\n",
    "                self.processed_image = invert_colors(self.processed_image)\n",
    "                self.inverted = True  # Set flag to prevent repeated inversion\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000\n",
    "        self.display_image(self.processed_image)\n",
    "        self.status_label.config(\n",
    "            text=f\"Status: {filter_function.__name__.replace('_', ' ').capitalize()} Applied in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def apply_thresholding(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.processed_image, self.otsu_threshold = thresholding(self.processed_image)\n",
    "\n",
    "        # Ask user if objects are black and invert if confirmed\n",
    "        if not hasattr(self, \"inverted\") and not hasattr(self, \"asked_about_inversion\"):\n",
    "            response = messagebox.askyesno(\"Invert Colors\", \"Are the objects black? If yes, they will be inverted.\")\n",
    "            if response:  # User confirmed\n",
    "                self.processed_image = invert_colors(self.processed_image)\n",
    "                self.inverted = True  # Ensure it only happens once\n",
    "            self.asked_about_inversion = True  # Prevent asking again\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000\n",
    "        self.display_image(self.processed_image)\n",
    "        self.status_label.config(\n",
    "            text=f\"Status: Thresholding Applied in {elapsed_time:.2f} ms (Otsu Threshold = {self.otsu_threshold:.2f})\")\n",
    "\n",
    "    def apply_labeling(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.processed_image, self.num_objects = labeling(self.processed_image)\n",
    "        elapsed_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        self.display_image(self.processed_image)\n",
    "        self.status_label.config(text=f\"Status: {self.num_objects} Objects Colored in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def apply_labeling_cc(self):\n",
    "        \"\"\" Applies Connected Component Labeling (CC) to detect objects. \"\"\"\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.status_label.config(text=\"Status: Counting and labelling objects using CC algorithm (this might take up to one minute)\")\n",
    "        self.status_label.update_idletasks()\n",
    "\n",
    "\n",
    "        # Convert to grayscale if necessary\n",
    "        if len(self.processed_image.shape) == 3:\n",
    "            gray_image = grayscale(self.processed_image)\n",
    "        else:\n",
    "            gray_image = self.processed_image\n",
    "\n",
    "        # Use checkbox value to determine if objects are black or white\n",
    "        is_black_objects = self.is_black_objects.get()\n",
    "\n",
    "        labeled_img, num_objects = labeling_cc(gray_image, is_black_objects)\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "        # Convert labeled image to uint8 for display\n",
    "        labeled_img = (labeled_img * (255 // max(1, num_objects))).astype(np.uint8)\n",
    "\n",
    "        self.processed_image = labeled_img\n",
    "        self.num_objects = num_objects\n",
    "        self.display_image(self.processed_image)\n",
    "\n",
    "        self.status_label.config(text=f\"Status: {num_objects} Objects Detected (CC) in {elapsed_time/1000:.3f} seconds\")\n",
    "        print(f\"Process Step: CC Labeling completed in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def apply_BFS_labelling(self):\n",
    "        \"\"\" Applies BFS Labeling while keeping objects white. \"\"\"\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Convert to grayscale if necessary\n",
    "        if len(self.processed_image.shape) == 3:\n",
    "            gray_image = grayscale(self.processed_image)\n",
    "        else:\n",
    "            gray_image = self.processed_image\n",
    "\n",
    "        # Use checkbox value to determine if objects are black or white\n",
    "        is_black_objects = self.is_black_objects.get()\n",
    "\n",
    "        labeled_img, num_objects = BFS_labelling(gray_image)\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "        self.processed_image = labeled_img  # Update the image to show labels\n",
    "        self.num_objects = num_objects\n",
    "        self.display_image(self.processed_image)\n",
    "\n",
    "        self.status_label.config(text=f\"Status: {num_objects} Objects Detected (BFS) in {elapsed_time:.2f} ms\")\n",
    "        print(f\"Process Step: BFS Labeling completed in {elapsed_time:.2f} ms\")\n",
    "\n",
    "    def count_objects_only(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first!\")\n",
    "            return\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Convert to grayscale if needed\n",
    "        if len(self.processed_image.shape) == 3:\n",
    "            gray_image = grayscale(self.processed_image)\n",
    "        else:\n",
    "            gray_image = self.processed_image\n",
    "\n",
    "        # Apply thresholding\n",
    "        _, binary_img = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Perform connected components analysis\n",
    "        num_labels, _, _, _ = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "        # Exclude background (label 0)\n",
    "        object_count = num_labels - 1\n",
    "\n",
    "        self.status_label.config(text=f\"Status: Counted {object_count} Objects using threshold method in {elapsed_time:.3f} ms\")\n",
    "\n",
    "    def load_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg;*.bmp\")])\n",
    "        if file_path:\n",
    "            self.image_path = file_path\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is not None:\n",
    "                self.original_image = img.copy()\n",
    "                self.processed_image = img.copy()\n",
    "                self.is_grayscale = False\n",
    "                self.inverted = False  # Reset inversion state\n",
    "                self.is_black_objects.set(False)  # Reset checkbox state\n",
    "                self.display_image(self.processed_image)\n",
    "                self.status_label.config(text=\"Status: Image Loaded\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Failed to load image. Please try another file.\")\n",
    "\n",
    "    def display_image(self, img):\n",
    "        img_resized = resize_image(img)\n",
    "        img_pil = Image.fromarray(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "        self.img_tk = ImageTk.PhotoImage(img_pil)\n",
    "        self.canvas.create_image(250, 250, anchor=tk.CENTER, image=self.img_tk)\n",
    "        self.canvas.image = self.img_tk\n",
    "\n",
    "    def reset_image(self):\n",
    "        \"\"\" Resets the processed image to the original state and resets UI elements. \"\"\"\n",
    "        if self.original_image is not None:\n",
    "            self.processed_image = self.original_image.copy()\n",
    "            self.is_grayscale = False\n",
    "            self.inverted = False  # Reset inversion state\n",
    "            self.is_black_objects.set(False)  # Reset \"Objects are Black\" checkbox\n",
    "            self.is_preprocess.set(False)  # Reset \"Preprocess Image\" checkbox\n",
    "            self.display_image(self.processed_image)\n",
    "            self.status_label.config(text=\"Status: Image Reset\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"No image to reset!\")\n",
    "\n",
    "    def save_image(self):\n",
    "        if self.processed_image is None:\n",
    "            messagebox.showerror(\"Error\", \"No processed image to save!\")\n",
    "            return\n",
    "\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".png\",\n",
    "                                                 filetypes=[(\"PNG files\", \"*.png\"),\n",
    "                                                            (\"JPEG files\", \"*.jpg\"),\n",
    "                                                            (\"BMP files\", \"*.bmp\")])\n",
    "        if file_path:\n",
    "            cv2.imwrite(file_path, self.processed_image)\n",
    "            self.status_label.config(text=\"Status: Image Saved\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ImageProcessorApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
