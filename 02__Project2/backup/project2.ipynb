{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1acb55",
   "metadata": {},
   "source": [
    "### PROJECT 2 - Artificial Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c764c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing labelling from file...\n",
      "Labels loaded successfully!\n",
      "Total number of detected objects: 49\n",
      "\n",
      "Feature Matrix (first 5 samples):\n",
      "     area   perimeter  aspect_ratio    extent  circularity  hu_moment_0  \\\n",
      "0  4126.0  258.509667      0.626374  0.795450     0.775864     0.182915   \n",
      "1  8261.0  356.877197      0.843090  0.760314     0.815089     0.165194   \n",
      "2  7724.0  369.705624      0.458333  0.810459     0.710134     0.212674   \n",
      "3  6642.5  336.835567      0.502103  0.795416     0.735708     0.203383   \n",
      "4  6264.5  326.208150      0.508065  0.801907     0.739787     0.203108   \n",
      "\n",
      "   hu_moment_1  hu_moment_2   hu_moment_3   hu_moment_4  ...  \\\n",
      "0     0.006636     0.000387  1.676352e-05 -9.094973e-10  ...   \n",
      "1     0.000878     0.000184  4.773698e-07 -3.585221e-12  ...   \n",
      "2     0.019540     0.000104  7.112114e-06 -1.859996e-10  ...   \n",
      "3     0.015911     0.000002  2.828842e-07  1.447039e-13  ...   \n",
      "4     0.015482     0.000088  8.741074e-06  4.780459e-11  ...   \n",
      "\n",
      "   color_skewness_0  color_std_1  color_skewness_1  color_std_2  \\\n",
      "0          0.218278    19.300486         -0.695169    14.732417   \n",
      "1         -0.948705    20.910975         -1.602520    12.416048   \n",
      "2         -2.092970    11.478530         -3.104701    10.697262   \n",
      "3         -2.438862    11.753374         -2.942530    10.101795   \n",
      "4         -1.671597    14.423053         -2.206415    11.792128   \n",
      "\n",
      "   color_skewness_2  texture_contrast  texture_correlation  texture_energy  \\\n",
      "0         -1.770181          0.219192             0.986415        0.448702   \n",
      "1         -1.806626          0.720862             0.977983        0.573759   \n",
      "2         -2.429814          0.615171             0.962945        0.727984   \n",
      "3         -1.924620          0.626240             0.967513        0.718854   \n",
      "4         -2.598555          0.221448             0.984246        0.662701   \n",
      "\n",
      "   texture_homogeneity  class  \n",
      "0             0.910184      B  \n",
      "1             0.907102      B  \n",
      "2             0.892214      A  \n",
      "3             0.884455      A  \n",
      "4             0.936015      A  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Features to drop due to high correlation:\n",
      "['perimeter', 'circularity', 'hu_moment_0', 'hu_moment_1', 'color_skewness_0', 'color_std_1', 'color_skewness_1', 'texture_energy']\n",
      "\n",
      "Selected training features:\n",
      "['area', 'aspect_ratio', 'extent', 'hu_moment_2', 'hu_moment_3', 'hu_moment_4', 'hu_moment_5', 'hu_moment_6', 'major_axis', 'minor_axis', 'color_std_0', 'color_std_2', 'color_skewness_2', 'texture_contrast', 'texture_correlation', 'texture_homogeneity', 'class']\n",
      "Aspect Ratios and Labels for Each Object:\n",
      "Object 1: Aspect Ratio = 0.6263736263736264, Label = B\n",
      "Object 2: Aspect Ratio = 0.8430901831084859, Label = B\n",
      "Object 3: Aspect Ratio = 0.4583333553785332, Label = A\n",
      "Object 4: Aspect Ratio = 0.5021026136015946, Label = A\n",
      "Object 5: Aspect Ratio = 0.5080645161290323, Label = A\n",
      "Object 6: Aspect Ratio = 0.8638663757424624, Label = B\n",
      "Object 7: Aspect Ratio = 0.9565217967967617, Label = B\n",
      "Object 8: Aspect Ratio = 0.911504424778761, Label = B\n",
      "Object 9: Aspect Ratio = 0.8994612374424055, Label = B\n",
      "Object 10: Aspect Ratio = 0.4636678409035367, Label = A\n",
      "Object 11: Aspect Ratio = 0.5140217018233779, Label = A\n",
      "Object 12: Aspect Ratio = 0.972631654899692, Label = B\n",
      "Object 13: Aspect Ratio = 0.8664976940318788, Label = B\n",
      "Object 14: Aspect Ratio = 0.4858387240728077, Label = A\n",
      "Object 15: Aspect Ratio = 0.5177214923666226, Label = A\n",
      "Object 16: Aspect Ratio = 0.5074073829085817, Label = A\n",
      "Object 17: Aspect Ratio = 0.8641744787704253, Label = B\n",
      "Object 18: Aspect Ratio = 0.934404263780736, Label = B\n",
      "Object 19: Aspect Ratio = 0.9017857142857143, Label = B\n",
      "Object 20: Aspect Ratio = 0.9342657487726199, Label = B\n",
      "Object 21: Aspect Ratio = 0.46153842941933354, Label = A\n",
      "Object 22: Aspect Ratio = 0.5146892671216828, Label = A\n",
      "Object 23: Aspect Ratio = 0.8983050847457628, Label = B\n",
      "Object 24: Aspect Ratio = 0.8555208312622271, Label = B\n",
      "Object 25: Aspect Ratio = 0.47822614018113285, Label = A\n",
      "Object 26: Aspect Ratio = 0.5197445217383251, Label = A\n",
      "Object 27: Aspect Ratio = 0.4674122626410993, Label = A\n",
      "Object 28: Aspect Ratio = 0.8658224793495329, Label = B\n",
      "Object 29: Aspect Ratio = 0.9316628799240798, Label = B\n",
      "Object 30: Aspect Ratio = 0.9350612242000113, Label = B\n",
      "Object 31: Aspect Ratio = 0.9463658931891777, Label = B\n",
      "Object 32: Aspect Ratio = 0.4466750090116514, Label = A\n",
      "Object 33: Aspect Ratio = 0.533404684033102, Label = A\n",
      "Object 34: Aspect Ratio = 0.9153261104709134, Label = B\n",
      "Object 35: Aspect Ratio = 0.898897078332291, Label = B\n",
      "Object 36: Aspect Ratio = 0.8180627942874562, Label = B\n",
      "Object 37: Aspect Ratio = 0.5390702891766743, Label = A\n",
      "Object 38: Aspect Ratio = 0.5197401030036616, Label = A\n",
      "Object 39: Aspect Ratio = 0.864, Label = B\n",
      "Object 40: Aspect Ratio = 0.45205476490831853, Label = A\n",
      "Object 41: Aspect Ratio = 0.7988506477694157, Label = B\n",
      "Object 42: Aspect Ratio = 0.921270625378713, Label = B\n",
      "Object 43: Aspect Ratio = 0.8914140680065012, Label = B\n",
      "Object 44: Aspect Ratio = 0.787584128256834, Label = B\n",
      "Object 45: Aspect Ratio = 0.5166217415004046, Label = A\n",
      "Object 46: Aspect Ratio = 0.5121412096940928, Label = A\n",
      "Object 47: Aspect Ratio = 0.8650154149554738, Label = B\n",
      "Object 48: Aspect Ratio = 0.4406846989100103, Label = A\n",
      "Object 49: Aspect Ratio = 0.8946548666270182, Label = B\n",
      "Aspect Ratio Cutoff: 0.6870465295875668\n",
      "\n",
      "Processing test image: imgs\\nuts_cam2_6.bmp\n",
      "Test sample 0: Predicted B, Probabilities: {'B': 1.0}\n",
      "Test sample 1: Predicted B, Probabilities: {'B': 1.0}\n",
      "Test sample 2: Predicted B, Probabilities: {'B': 1.0}\n",
      "Test sample 3: Predicted A, Probabilities: {'A': 1.0}\n",
      "Test sample 4: Predicted A, Probabilities: {'A': 1.0}\n",
      "Test sample 5: Predicted A, Probabilities: {'A': 1.0}\n",
      "Test sample 6: Predicted B, Probabilities: {'B': 1.0}\n",
      "Test sample 7: Predicted A, Probabilities: {'A': 1.0}\n",
      "Test sample 8: Predicted B, Probabilities: {'B': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops \n",
    "from scipy.stats import skew, multivariate_normal\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Functions  -------------------------------------------------------------------------------------------------------------------------- ###\n",
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------------- ###\n",
    "\n",
    "def pre_process_and_extract_features(image):\n",
    "    \"\"\"Given a BGR image, perform preprocessing, contour extraction and feature extraction.\n",
    "       Returns a list of feature dictionaries (one per detected object) and contours.\"\"\"\n",
    "       \n",
    "    kernel_size = 5\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    median_img = cv2.medianBlur(gray_img, kernel_size)\n",
    "    if len(median_img.shape) == 3:\n",
    "        median_img = cv2.cvtColor(median_img, cv2.COLOR_BGR2GRAY)\n",
    "    otsu_threshold, binary_img = cv2.threshold(median_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    features = []\n",
    "    for i, contour in enumerate(contours):\n",
    "\n",
    "        ### -------------------------------------------------------------------------------- ###\n",
    "        ### --------------------------- Simple features            ------------------------- ###\n",
    "        ### -------------------------------------------------------------------------------- ###\n",
    "        \n",
    "        #1) Feature 1 - area\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        #2) Feature 2 - perimeter\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "        #3) Feature 3 - centroid\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid = (int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"]))\n",
    "        else:\n",
    "            centroid = (0, 0)\n",
    "        \n",
    "        #4) Feature 4 - Mean colour\n",
    "        mask = np.zeros(binary_img.shape, dtype=\"uint8\")\n",
    "        cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "        mean_color = cv2.mean(image, mask=mask)\n",
    "\n",
    "        ### -------------------------------------------------------------------------------- ###\n",
    "        ### --------------------------- Complex features            ------------------------ ###\n",
    "        ### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "        #5) Feature 5 - Rotated rectangle\n",
    "        rotated_rect = cv2.minAreaRect(contour)\n",
    "        rotated_box = cv2.boxPoints(rotated_rect)\n",
    "        rotated_box = rotated_box.astype(np.intp)\n",
    "        w_rot, h_rot = rotated_rect[1]\n",
    "\n",
    "        #6) Feature 6 - Aspect ratio\n",
    "        aspect_ratio = float(min(w_rot, h_rot)) / max(w_rot, h_rot) if min(w_rot, h_rot) != 0 else 0\n",
    "\n",
    "        #7) Feature 7 - Extent\n",
    "        extent = area / (w_rot * h_rot) if (w_rot * h_rot) != 0 else 0\n",
    "\n",
    "        #8) Feature 8 - Circularity\n",
    "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0\n",
    "\n",
    "        #9) Feature 9 - Hu moments\n",
    "        hu_moments = cv2.HuMoments(M).flatten()\n",
    "\n",
    "        #10) Feature 10 - Major and minor axis lengths\n",
    "        if len(contour) >= 5:\n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            major_axis = max(ellipse[1])\n",
    "            minor_axis = min(ellipse[1])\n",
    "        else:\n",
    "            major_axis, minor_axis = 0, 0\n",
    "        \n",
    "        #11) Feature 11 - Color standard deviation and skewness\n",
    "        color_moments = {}\n",
    "        for idx, channel in enumerate(cv2.split(image)):\n",
    "            channel_vals = channel[mask == 255]\n",
    "            if channel_vals.size > 0:\n",
    "                channel_std = np.std(channel_vals)\n",
    "                channel_skew = skew(channel_vals.astype(np.float64))\n",
    "            else:\n",
    "                channel_mean, channel_std, channel_skew = 0, 0, 0\n",
    "            color_moments[f'channel_{idx}'] = {'std': channel_std, 'skewness': channel_skew}\n",
    "        \n",
    "\n",
    "        #12) Feature 12 - Texture features using GLCM\n",
    "        box_center = rotated_rect[0]\n",
    "        box_size = rotated_rect[1]\n",
    "        angle = rotated_rect[2]\n",
    "        if angle < -45:\n",
    "            angle += 90\n",
    "            box_size = (box_size[1], box_size[0])\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(box_center, angle, 1.0)\n",
    "        rotated_gray = cv2.warpAffine(gray_img, rotation_matrix, (gray_img.shape[1], gray_img.shape[0]))\n",
    "        roi = cv2.getRectSubPix(rotated_gray, (int(box_size[0]), int(box_size[1])), box_center)\n",
    "        roi_quant = (roi // 16).astype(np.uint8)\n",
    "        glcm = graycomatrix(roi_quant, distances=[1], angles=[0], levels=16, symmetric=True, normed=True)\n",
    "        texture_features = {\n",
    "            'contrast': graycoprops(glcm, 'contrast')[0, 0],\n",
    "            'correlation': graycoprops(glcm, 'correlation')[0, 0],\n",
    "            'energy': graycoprops(glcm, 'energy')[0, 0],\n",
    "            'homogeneity': graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        }\n",
    "        \n",
    "        feat = {\n",
    "            \"object\": i + 1,\n",
    "            \"area\": area,\n",
    "            \"perimeter\": perimeter,\n",
    "            \"centroid\": centroid,\n",
    "            \"mean_color\": mean_color,\n",
    "            \"aspect_ratio\": aspect_ratio,\n",
    "            \"extent\": extent,\n",
    "            \"circularity\": circularity,\n",
    "            \"hu_moments\": hu_moments.tolist(),\n",
    "            \"major_axis\": major_axis,\n",
    "            \"minor_axis\": minor_axis,\n",
    "            \"color_moments\": color_moments,\n",
    "            \"texture\": texture_features,\n",
    "            \"rotated_box\": rotated_box\n",
    "        }\n",
    "        features.append(feat)\n",
    "    return features, contours\n",
    "\n",
    "def draw_boxes(image, features, labels=None):\n",
    "    \"\"\"Draw bounding boxes (and optionally, labels) on a copy of the image.\"\"\"\n",
    "    img_copy = image.copy()\n",
    "    for feat in features:\n",
    "        color = (0, 255, 0)  # default for class B\n",
    "        text = \"\"\n",
    "        if labels is not None:\n",
    "            # labels list is assumed to be in the same order as features (object index starting at 1)\n",
    "            idx = feat[\"object\"] - 1\n",
    "            if labels[idx] == \"A\":\n",
    "                color = (0, 0, 255)  # red for class A\n",
    "                text = \"A\"\n",
    "            else:\n",
    "                color = (0, 255, 0)\n",
    "                text = \"B\"\n",
    "        pts = feat.get('rotated_box')\n",
    "        cv2.polylines(img_copy, [pts], isClosed=True, color=color, thickness=2)\n",
    "\n",
    "        (cx, cy) = feat[\"centroid\"]\n",
    "        cv2.putText(img_copy, f\"{feat['object']} {text}\", (cx, cy),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "    return img_copy\n",
    "\n",
    "def manual_labeling(image, features ,path):\n",
    "    \"\"\"\n",
    "    Displays the whole image with all bounding boxes.\n",
    "    The user clicks on boxes that should be labeled as Class A.\n",
    "    Boxes not clicked are labeled as Class B.\n",
    "    Press 'q' to finish labeling.\n",
    "    Returns a list of labels corresponding to the features.\n",
    "    \"\"\"\n",
    "    manual_labels = ['B'] * len(features)  # default label is 'B'\n",
    "    image_with_boxes = draw_boxes(image, features)\n",
    "\n",
    "    window_title = \"Labelling from picture: \" + path\n",
    "    instructions = \"Click on boxes for Class A to label them as A. Press 'q' to finish.\"\n",
    "\n",
    "    cv2.putText(image_with_boxes, instructions, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    def click_event(event, x, y, flags, param):\n",
    "            nonlocal manual_labels, image_with_boxes\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                # Iterate over each feature to check if the click falls inside its box.\n",
    "                for i, feat in enumerate(features):\n",
    "                    inside = False\n",
    "                    pts = feat.get('rotated_box')\n",
    "                    if pts is not None:\n",
    "                        # Check if the click point falls inside the rotated polygon.\n",
    "                        if cv2.pointPolygonTest(pts, (x, y), False) >= 0:\n",
    "                            inside = True\n",
    "                    else:\n",
    "                        # Fallback: check the axis-aligned bounding box.\n",
    "                        bx, by, bw, bh = feat.get('bbox', (0, 0, 0, 0))\n",
    "                        if bx <= x <= bx + bw and by <= y <= by + bh:\n",
    "                            inside = True\n",
    "                    if inside:\n",
    "                        # Toggle the label: if already 'A', change it to 'B'; if 'B', change to 'A'\n",
    "                        manual_labels[i] = 'B' if manual_labels[i] == 'A' else 'A'\n",
    "                        # Redraw the entire image using the updated labels.\n",
    "                        image_with_boxes = draw_boxes(image, features, labels=manual_labels)\n",
    "                        # Optionally, you can add the instructions text again.\n",
    "                        cv2.putText(image_with_boxes, instructions, (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                        cv2.imshow(window_title, image_with_boxes)\n",
    "                        break\n",
    "\n",
    "    cv2.namedWindow(window_title)\n",
    "    cv2.setMouseCallback(window_title, click_event)\n",
    "    while True:\n",
    "        cv2.imshow(window_title, image_with_boxes)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyWindow(window_title)\n",
    "    return manual_labels\n",
    "\n",
    "def flatten_features(features):\n",
    "    \"\"\"Convert a list of feature dictionaries into a flat dictionary for DataFrame creation.\"\"\"\n",
    "    feature_vectors = []\n",
    "    for feat in features:\n",
    "        vector = {\n",
    "           'area': feat['area'],\n",
    "           'perimeter': feat['perimeter'],\n",
    "           'aspect_ratio': feat['aspect_ratio'],\n",
    "           'extent': feat['extent'],\n",
    "           'circularity': feat['circularity'],\n",
    "           'hu_moment_0': feat['hu_moments'][0],\n",
    "           'hu_moment_1': feat['hu_moments'][1],\n",
    "           'hu_moment_2': feat['hu_moments'][2],\n",
    "           'hu_moment_3': feat['hu_moments'][3],\n",
    "           'hu_moment_4': feat['hu_moments'][4],\n",
    "           'hu_moment_5': feat['hu_moments'][5],\n",
    "           'hu_moment_6': feat['hu_moments'][6],\n",
    "           'major_axis': feat['major_axis'],\n",
    "           'minor_axis': feat['minor_axis'],\n",
    "           'color_std_0': feat['color_moments']['channel_0']['std'],\n",
    "           'color_skewness_0': feat['color_moments']['channel_0']['skewness'],\n",
    "           'color_std_1': feat['color_moments']['channel_1']['std'],\n",
    "           'color_skewness_1': feat['color_moments']['channel_1']['skewness'],\n",
    "           'color_std_2': feat['color_moments']['channel_2']['std'],\n",
    "           'color_skewness_2': feat['color_moments']['channel_2']['skewness'],\n",
    "           'texture_contrast': feat['texture']['contrast'],\n",
    "           'texture_correlation': feat['texture']['correlation'],\n",
    "           'texture_energy': feat['texture']['energy'],\n",
    "           'texture_homogeneity': feat['texture']['homogeneity']\n",
    "        }\n",
    "        feature_vectors.append(vector)\n",
    "    return feature_vectors\n",
    "\n",
    "def select_features_by_correlation(corr_matrix, threshold=0.9):\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column].abs() > threshold)]\n",
    "    return to_drop\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Classifiers for training    ------------------------ ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "def train_classifier(df_train, method=\"bayes_big\", k_neighbors=3):\n",
    "    \"\"\"Train a classifier based on the selected method.\"\"\"\n",
    "\n",
    "    if method == \"bayes_big\":\n",
    "        return train_classifier_bayes_big(df_train)\n",
    "    elif method == \"bayes_naive\":\n",
    "        return train_classifier_bayes_naive(df_train)\n",
    "    elif method == \"aspect_ratio\":\n",
    "        return train_classifier_aspect_ratio(df_train)\n",
    "    elif method == \"kNN\":\n",
    "        return train_classifier_kNN(df_train, k_neighbors)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported classifier method. Use 'bayes'.\") \n",
    "    \n",
    "def train_classifier_bayes_naive(df_train):\n",
    "    \"\"\"\n",
    "    Train a simple naive Bayes classifier using all features (except the 'class' column).\n",
    "    Returns a dictionary where each key is a class label and each value is a tuple\n",
    "    (mean_vec, var_vec, prior), where mean_vec and var_vec are numpy arrays.\n",
    "    \"\"\"\n",
    "    # Use all feature columns except \"class\"\n",
    "    feature_cols = df_train.columns.drop(\"class\")\n",
    "    classes = df_train[\"class\"].unique()\n",
    "    class_params = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        group = df_train[df_train[\"class\"] == cls]\n",
    "        # Compute the mean and variance for each feature\n",
    "        mean_vec = group[feature_cols].mean().values\n",
    "        var_vec = group[feature_cols].var().values\n",
    "        # Replace any zero variance with a very small number to avoid division by zero\n",
    "        var_vec[var_vec == 0] = 1e-6\n",
    "        # Compute class prior\n",
    "        prior = len(group) / len(df_train)\n",
    "        class_params[cls] = (mean_vec, var_vec, prior)\n",
    "    \n",
    "    return class_params\n",
    "\n",
    "def train_classifier_bayes_big(df_train):\n",
    "    \"\"\"Compute mean vectors, covariance matrices and priors for each class.\"\"\"\n",
    "    classes = df_train['class'].unique()\n",
    "    class_params = {}\n",
    "    for cls in classes:\n",
    "        group = df_train[df_train['class'] == cls]\n",
    "        feature_cols = group.columns.drop('class')\n",
    "        mean_vec = group[feature_cols].mean().values\n",
    "        cov_mat = group[feature_cols].cov().values\n",
    "        prior = len(group) / len(df_train)\n",
    "        class_params[cls] = (mean_vec, cov_mat, prior)\n",
    "    return class_params\n",
    "\n",
    "def train_classifier_kNN(df_train, k_neighbors):\n",
    "    \"\"\"Train a kNN classifier using the specified number of neighbors.\"\"\"\n",
    "\n",
    "    feature_cols = df_train.columns.drop(\"class\")\n",
    "\n",
    "    X_full = df_train[feature_cols].values\n",
    "    y_full = df_train[\"class\"].values\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=5)        #select 5 best features, can be tuned\n",
    "    X_train_selected = selector.fit_transform(X_full, y_full)\n",
    "\n",
    "    # Get names of selected features\n",
    "    selected_feature_mask = selector.get_support()\n",
    "    selected_features = feature_cols[selected_feature_mask]\n",
    "    print(\"Top features selected:\", selected_features.tolist())\n",
    "\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier(k_neighbors) \n",
    "    knn_classifier.fit(X_train_selected, y_full)  \n",
    "\n",
    "    return knn_classifier, selector\n",
    "\n",
    "def train_classifier_aspect_ratio(df_train):\n",
    "    \"\"\"Train a classifier based on aspect ratio.\"\"\"\n",
    "\n",
    "    print(\"Aspect Ratios and Labels for Each Object:\")\n",
    "\n",
    "    for idx, row in df_train.iterrows():\n",
    "        print(f\"Object {idx+1}: Aspect Ratio = {row['aspect_ratio']}, Label = {row['class']}\")\n",
    "\n",
    "    group_means = df_train.groupby(\"class\")[\"aspect_ratio\"].mean()\n",
    "    \n",
    "    # For simplicity, this classifier is intended for binary classification.\n",
    "    if len(group_means) != 2:\n",
    "        raise ValueError(\"This aspect ratio classifier expects exactly two classes.\")\n",
    "    \n",
    "    # Sort the groups by their mean aspect ratio so we know which is lower and which is higher.\n",
    "    sorted_groups = group_means.sort_values()\n",
    "    lower_class = sorted_groups.index[0]\n",
    "    higher_class = sorted_groups.index[1]\n",
    "    cutoff = (sorted_groups.iloc[0] + sorted_groups.iloc[1]) / 2.0\n",
    "    \n",
    "    print(\"Aspect Ratio Cutoff:\", cutoff)\n",
    "\n",
    "\n",
    "    return {\"cutoff\": cutoff, \"lower_class\": lower_class, \"higher_class\": higher_class}\n",
    "\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Classifiers for prediction  ------------------------ ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "def classify_sample(x, class_params, method=\"bayes_big\"):\n",
    "\n",
    "    if method == \"bayes_big\":\n",
    "        return classify_sample_bayes_big(x, class_params)\n",
    "    elif method == \"bayes_naive\":\n",
    "        return classify_sample_bayes_naive(x, class_params)\n",
    "    elif method == \"kNN\":\n",
    "        return classify_sample_kNN(x, class_params)\n",
    "    else:\n",
    "        print(f\"---!! Unsupported classifier method {method}. Using 'bayes_big'.\")\n",
    "        return classify_sample_bayes_big(x, class_params)\n",
    "\n",
    "\n",
    "def classify_sample_bayes_big(x, class_params):\n",
    "    probabilities = {}\n",
    "    for cls, (mean_vec, cov_mat, prior) in class_params.items():\n",
    "        cov_mat_adjusted = cov_mat + np.eye(cov_mat.shape[0]) * 1e-6\n",
    "        likelihood = multivariate_normal.pdf(x, mean=mean_vec, cov=cov_mat_adjusted, allow_singular=True)\n",
    "        posterior = likelihood * prior\n",
    "        probabilities[cls] = posterior\n",
    "    predicted_class = max(probabilities, key=probabilities.get)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def classify_sample_bayes_naive(x_value, class_params):\n",
    "    \n",
    "    probabilities = {}\n",
    "    for cls, (mean_vec, var_vec, prior) in class_params.items():\n",
    "        # Calculate the Gaussian likelihood for each feature:\n",
    "        # p(x_i|C) = (1/sqrt(2*pi*var_i)) * exp( - (x_i - mean_i)^2 / (2*var_i) )\n",
    "        likelihoods = (1.0 / np.sqrt(2 * np.pi * var_vec)) * np.exp(- ((x - mean_vec) ** 2) / (2 * var_vec))\n",
    "        # Under the naive Bayes assumption, the joint likelihood is the product of individual likelihoods.\n",
    "        likelihood = np.prod(likelihoods)\n",
    "        # Multiply by the prior to get the unnormalized posterior.\n",
    "        posterior = likelihood * prior\n",
    "        probabilities[cls] = posterior\n",
    "    # Choose the class with the maximum posterior probability.\n",
    "    predicted_class = max(probabilities, key=probabilities.get)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "\n",
    "def classify_sample_aspect_ratio(x, aspect_params):\n",
    "    \"\"\"Classify a sample using the aspect ratio classifier.\"\"\"\n",
    "\n",
    "    aspect_value = x[\"aspect_ratio\"]\n",
    "\n",
    "    # Compare the value with the cutoff:\n",
    "    if aspect_value <= aspect_params[\"cutoff\"]:\n",
    "        predicted_class = aspect_params[\"lower_class\"]\n",
    "    else:\n",
    "        predicted_class = aspect_params[\"higher_class\"]\n",
    "    \n",
    "    # Create a dummy probability dictionary with 100% probability for the predicted class.\n",
    "    dummy_probability = {predicted_class: 1.0}\n",
    "\n",
    "    return predicted_class, dummy_probability\n",
    "\n",
    "def classify_sample_kNN(x, knn_params):\n",
    "    \"\"\"Classify a sample using the kNN classifier.\"\"\"\n",
    "\n",
    "    knn_classifier, selector = knn_params\n",
    "\n",
    "    # Ensure x is a 2D array (1 sample, n features).\n",
    "    x = x.reshape(1, -1)\n",
    "\n",
    "    # Transform the sample using the previously fitted selector.\n",
    "    x_selected = selector.transform(x)\n",
    "\n",
    "    # Get the predicted class.\n",
    "    predicted_class = knn_classifier.predict(x_selected)[0]\n",
    "\n",
    "    # Get class probabilities.\n",
    "    proba = knn_classifier.predict_proba(x_selected)[0]\n",
    "\n",
    "    # Map probabilities to class labels.\n",
    "    probabilities = {cls: p for cls, p in zip(knn_classifier.classes_, proba)}\n",
    "    return predicted_class, probabilities\n",
    "    \n",
    "\n",
    "\n",
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------------- ###\n",
    "### --------------------------- MAIN PART  -------------------------------------------------------------------------------------------------------------------------- ###\n",
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------------- ###\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Tuning variables      ------------------------------ ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "import_parameters = True    # Set to False to label manually\n",
    "                            # Set to True to load the labels from a file\n",
    "                            # FIRST TIME FOR RUNNING PROGRAM WITHOUT TRAINING FILE --> Set to False\n",
    "\n",
    "training_method = \"aspect_ratio\"     # Choose between:\n",
    "                                # 1) aspect_ratio -- Aspect Ratio and cutoff classifier\n",
    "                                # 2) bayes_naive -- using mean and variance\n",
    "                                # 3) bayes_big    -- using mean and covariance\n",
    "                                # 4) kNN          -- using KNN classifier\n",
    "\n",
    "k_neighbors = 9            # Number of neighbors for kNN classifier, 9 is good, max 49, cutoff 41\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Parameters        ---------------------------------- ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "images_paths = [\n",
    "    r\"imgs\\nuts_cam2_1.bmp\",\n",
    "    r\"imgs\\nuts_cam2_2.bmp\",\n",
    "    r\"imgs\\nuts_cam2_3.bmp\",\n",
    "    r\"imgs\\nuts_cam2_4.bmp\",\n",
    "    r\"imgs\\nuts_cam2_5.bmp\",\n",
    "    r\"imgs\\nuts_cam2_6.bmp\",\n",
    "]\n",
    "\n",
    "training_data_file_path = \"training_data.pkl\"  # Path to save/load training data\n",
    "\n",
    "#Split the images into training and testing sets\n",
    "prediction_length = 1\n",
    "training_length = len(images_paths) - prediction_length \n",
    "\n",
    "training_images_paths = images_paths[:training_length]\n",
    "testing_images_paths = images_paths[-prediction_length:]\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Object recognition and labelling ------------------- ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "if import_parameters:\n",
    "    print(\"Importing labelling from file...\")\n",
    "\n",
    "    try:\n",
    "        with open(training_data_file_path, \"rb\") as f:\n",
    "            df_train = pickle.load(f)\n",
    "        print(\"Labels loaded successfully!\")\n",
    "\n",
    "        print(\"Total number of detected objects:\", len(df_train))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {training_data_file_path} was not found. Please check the file path.\")\n",
    "        import_parameters = False  # Set to False to proceed with manual labeling.\n",
    "\n",
    "\n",
    "\n",
    "#Find the features and labels for the training images\n",
    "if not import_parameters:\n",
    "    training_features = []\n",
    "    training_labels = []\n",
    "\n",
    "    print(\"Starting training phase...\")\n",
    "\n",
    "    for path in training_images_paths:\n",
    "        print(f\"\\nProcessing training image: {path}\")\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        features, _ = pre_process_and_extract_features(img)\n",
    "\n",
    "        # Perform manual labeling on the full image.\n",
    "        img_with_boxes = draw_boxes(img, features)\n",
    "        labels = manual_labeling(img, features, path)\n",
    "        training_features.extend(features)\n",
    "        training_labels.extend(labels)\n",
    "    \n",
    "    train_vectors = flatten_features(training_features)\n",
    "    df_train = pd.DataFrame(train_vectors)\n",
    "    df_train['class'] = training_labels\n",
    "\n",
    "    # Save the manual labels in a pickle file.\n",
    "    with open(training_data_file_path, \"wb\") as f:\n",
    "        pickle.dump(df_train, f)\n",
    "\n",
    "    print(f\"\\nTotal training samples: {len(training_features)}\")\n",
    "\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Feature Extraction --------------------------------- ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "print(\"\\nFeature Matrix (first 5 samples):\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Perform correlation-based feature selection on training data. Important for kNN and bayes_simple\n",
    "\n",
    "corr_matrix = df_train.drop(columns=['class']).corr()\n",
    "features_to_drop = select_features_by_correlation(corr_matrix, threshold=0.9)\n",
    "\n",
    "print(\"\\nFeatures to drop due to high correlation:\")\n",
    "print(features_to_drop)\n",
    "\n",
    "selected_train = df_train.drop(columns=features_to_drop)\n",
    "\n",
    "print(\"\\nSelected training features:\")\n",
    "print(selected_train.columns.tolist())\n",
    "\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Training phase ------------------------------------- ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "class_params = train_classifier(selected_train, training_method, k_neighbors)\n",
    "\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "### --------------------------- Prediction phase  ---------------------------------- ###\n",
    "### -------------------------------------------------------------------------------- ###\n",
    "\n",
    "\n",
    "for test_path in testing_images_paths:\n",
    "    print(f\"\\nProcessing test image: {test_path}\")\n",
    "\n",
    "    test_img = cv2.imread(test_path)\n",
    "    test_feats, _ = pre_process_and_extract_features(test_img)\n",
    "    test_vectors = flatten_features(test_feats)\n",
    "\n",
    "    df_test = pd.DataFrame(test_vectors)\n",
    "    df_test = df_test.drop(columns=features_to_drop)\n",
    "\n",
    "    # Predict classes on each test sample.\n",
    "    predictions = []\n",
    "    for idx, row in df_test.iterrows():\n",
    "        if training_method == \"aspect_ratio\":\n",
    "            # Pass the entire row so that the aspect_ratio can be extracted by its key.\n",
    "            pred_class, probs = classify_sample_aspect_ratio(row, class_params)\n",
    "        else:\n",
    "            x = row.values\n",
    "            pred_class, probs = classify_sample(x, class_params, training_method)\n",
    "        predictions.append(pred_class)\n",
    "        print(f\"Test sample {idx}: Predicted {pred_class}, Probabilities: {probs}\")\n",
    "\n",
    "    # Display the test image with bounding boxes and predicted labels.\n",
    "    test_img_result = draw_boxes(test_img, test_feats, labels=predictions)\n",
    "    instructions = \"Predictions for test image.\"\n",
    "\n",
    "    cv2.putText(test_img_result, instructions, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    cv2.imshow(f\"Test Image Predictions for photo in {test_path}\", test_img_result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
